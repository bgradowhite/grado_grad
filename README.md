A small auto-grad implementation (largely following Kaparthy's Micrograd project), but upgraded to include tensors. 

Included is an engine with a Tensor class, defining the forward and backward steps for various tensor operations. 

nn and optim files define simple layers and a vanilla SGD function. 

Finally, the ipython file provides a test run, fitting MNIST data with a simple MLP network. 
